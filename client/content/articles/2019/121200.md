---
title: MediaRecorderを使って音声録音したら再生時間が取れなかった件
tags: [JavaScript, Nuxt.js, Firebase, SSR]
description: MediaRecorderAPIで長さが取れないという話と、webmをブラウザ上でwavに変換する話です
createdDate: '2019-12-12'
---

## はじめに

IPFactory Advent Calendar 2019 12日目の記事です。

<link-card title="IPFactory Advent Calendar 2019 - Qiita" text="IPFactoryによるアドベントカレンダー" link-url="https://qiita.com/advent-calendar/2019/ipfactory" img-src="/link_img/d4b6bd7b1a85f61b92f1dc0bc7902a1e9876d67d.png"></link-card>

インターン先で、ブラウザで音声入力からの音声解析してチャットボットぽいものを作る機会がありました。
その際、ブラウザでの音声入力で詰まった点があったので適当に書く予定です。

一応言っておきますが、全てPC版のChromeで試しています。Firefox等他のブラウザでは一切試していないのであしからず。

## MediaRecorderを使ってサクッと音声録音してみよう

まず、ブラウザで音声入力をするにはどうすればいいだろうか？  
調べてみたところWebRTCという技術があり、`getUserMedia`と`MediaRecorder`というものを使えば楽に音声入力が実現できそうでした。

ということでサクッとJSから音声録音を実現するために書いたコードが以下のものとなっています。

<link-card title="mnao305/webrtc_recording_test" text="JSを使ってブラウザ上で録音をしてみるテスト. Contribute to mnao305/webrtc_recording_test development by creating an account on GitHub." link-url="https://github.com/mnao305/webrtc_recording_test" img-src="/link_img/ab3abdd2c08124837cb27f46b8909886f24e490c.png"></link-card>

```js[main.js]
let mediaRecorder
let stream
let url

// ボタンとか取ってきてるだけ
const btn = document.getElementById('recordingBtn')
const player = document.getElementById('player')
const downloadLink = document.getElementById('downloadLink')
const status = document.getElementById('recordingStatus')

// ボタンがクリックされたら
btn.addEventListener('click', async () => {
  // ここでマイクの使用許可をユーザに求める
  stream = await navigator.mediaDevices.getUserMedia({
    audio: true,
    video: false
  })
  // urlがもうすでに存在していたら開放する
  if(url) URL.revokeObjectURL(url)
  status.style = 'display: inline;'
  downloadLink.style = 'display: none;'
  player.src = ''
  captureStart()
  setTimeout(() => {
    // 10秒後に停止する
    captureStop()
    status.style = 'display: none;'
    downloadLink.style = 'display: inline;'
  }, 10 * 1000);
})

function captureStart() {
  // マイクからのメディアストリームを記録する
  mediaRecorder = new MediaRecorder(stream, {
    // Chromeではwebmしか使えない、らしい。
    mimeType: 'audio/webm',
  })
  mediaRecorder.start();
}

function captureStop() {
  mediaRecorder.stop()

  mediaRecorder.ondataavailable = (e) => {
    // Blobデータが利用可能になったら、そのデータのURLをプレイヤーとリンクに入れる
    url = URL.createObjectURL(e.data)
    player.src = url
    downloadLink.href = url
  }
  // デバイスの開放。これをしないとマイクがずっとキャプチャ状態になるよ
  stream.getTracks().forEach(track => track.stop());
}
```

デモページも用意しました。下記リンクに飛べば実際に録音して、再生、ダウンロードを試すことができます。

<link-card title="JSで録音してみるテスト" link-url="https://mnao305.github.io/webrtc_recording_test/01/index.html"></link-card>

録音ボタンを押すと録音が開始されますが、その際ブラウザからマイクの許可が求められます。

ソースコード内のコメントでも書いてあるが、MediaRecorderではwebmしか使えないらしい。
webmとはGoogleが開発しているフリーのメディアフォーマット。

今回はwavを使いたかったのでそれも後ほど解決します。

## 動画長さが存在しない

さて、上記のデモを試してみたらわかるが、この録音した音声データには再生時間が存在していません。

```shell
> ffprobe test.webm -hide_banner
Input #0, matroska,webm, from 'test.webm':
  Metadata:
    encoder         : Chrome
  Duration: N/A, start: 0.000000, bitrate: N/A
```

色々と調べてみたところ、これはChromeのバグとして報告されていました。

<link-card title="642012 - chromium - An open-source project to help move the web forward. - Monorail" link-url="[undefined](https://bugs.chromium.org/p/chromium/issues/detail?id=642012)"></link-card>

ですが、WontFixとなっています。  
上記Issueにも書いてある通り、W3Cの方のIssueにも上がっていました。

<link-card title="Creation of Seekable Files · Issue #119 · w3c/mediacapture-record" text="At the moment implementations of the MediaStream Recording API don&#39;t write seekable webm files. The WebM format doesn&#39;t make this particularly easy, as to write the cues in a useful fashion..." link-url="https://github.com/w3c/mediacapture-record/issues/119" img-src="/link_img/3a2144c76fd3af1aa417f9d442cd97f6643bbac0.png"></link-card>

ということでこれはバグと言うより仕様みたいです。

## webmではなくwavで保存し、動画長さを追加する

色々と試してみた結果、解決するために実際にやったのはファイルヘッダを書き換えてwavにするという方法です。

コードを見てもらったほうがわかりやすいと思うので、下記にGitHubへのリンクを張っておきます。

<link-card title="mnao305/webrtc_recording_test" text="JSを使ってブラウザ上で録音をしてみるテスト. Contribute to mnao305/webrtc_recording_test development by creating an account on GitHub." link-url="https://github.com/mnao305/webrtc_recording_test" img-src="/link_img/ab3abdd2c08124837cb27f46b8909886f24e490c.png"></link-card>

デモページ

<link-card title="JSで録音してみるテスト to wav" link-url="https://mnao305.github.io/webrtc_recording_test/02/index.html"></link-card>

wavで保存され再生時間も取れているのがわかる。

```shell
> ffprobe.exe test.wav -hide_banner
Input #0, wav, from 'test.wav':
  Duration: 00:00:10.77, bitrate: 705 kb/s
    Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 44100 Hz, 1 channels, s16, 705 kb/s
```

この方法の何が嬉しいかというと、wavにできること、追加でライブラリがいらないことなどですかね。  
ということでコードの説明を軽くします。

// TODO 後で書く

```js[main.js]
import Recorder from "./lib/recorder.js"

// ボタンとか取ってきてるだけ
const btn = document.getElementById("recordingBtn")
const player = document.getElementById("player")
const downloadLink = document.getElementById("downloadLink")
const status = document.getElementById("recordingStatus")
const recorder = new Recorder()

// ボタンがクリックされたら
btn.addEventListener("click", () => {
  status.style = "display: inline;"
  downloadLink.style = "display: none;"
  player.src = ""
  recorder.start()
  setTimeout(() => {
    // 10秒後に停止する
    const url = recorder.stop()
    player.src = url
    downloadLink.href = url
    status.style = "display: none;"
    downloadLink.style = "display: inline;"
  }, 10 * 1000)
})
```

```js[lib/recorder.js]
import Encoder from "./encoder.js"

export default class {
  constructor() {
    this.encoderOptions = {
      bitRate: 128,
      sampleRate: 44100
    }

    this.bufferSize = 4096

    this.wavSamples = []
    this.stream = null
    this.context = null
    this.input = null
    this.processor = null
  }

  async start() {
    this.stream = await navigator.mediaDevices.getUserMedia({
      audio: true,
      video: false
    })
    this.captureStart()
  }

  stop() {
    this.stream.getTracks().forEach((track) => track.stop())
    this.input.disconnect()
    this.processor.disconnect()
    this.context.close()


    const encoder = new Encoder({
      bufferSize: this.bufferSize,
      sampleRate: this.encoderOptions.sampleRate,
      samples: this.wavSamples
    })
    const url = encoder.finish()
    this.wavSamples = []

    return url
  }

  captureStart() {
    this.context = new window.AudioContext()
    this.input = this.context.createMediaStreamSource(this.stream)
    this.processor = this.context.createScriptProcessor(this.bufferSize, 1, 1)

    this.processor.onaudioprocess = (ev) => {
      const sample = ev.inputBuffer.getChannelData(0)
      this.wavSamples.push(new Float32Array(sample))
    }

    this.input.connect(this.processor)
    this.processor.connect(this.context.destination)
  }
}
```

```js[lib/encoder.js]
export default class {
  constructor(options) {
    this.bufferSize = options.bufferSize || 4096
    this.sampleRate = options.sampleRate
    this.samples = options.samples
  }

  finish() {
    this.joinSamples()

    let buffer = new ArrayBuffer(44 + this.samples.length * 2)
    let view = new DataView(buffer)

    // ファイルヘッダいじいじ
    this.writeString(view, 0, "RIFF")
    view.setUint32(4, 36 + this.samples.length * 2, true)
    this.writeString(view, 8, "WAVE")
    this.writeString(view, 12, "fmt ")
    view.setUint32(16, 16, true)
    view.setUint16(20, 1, true)
    view.setUint16(22, 1, true)
    view.setUint32(24, this.sampleRate, true)
    view.setUint32(28, this.sampleRate * 4, true)
    view.setUint16(32, 4, true)
    view.setUint16(34, 16, true)
    this.writeString(view, 36, "data")
    view.setUint32(40, this.samples.length * 2, true)

    this.floatTo16BitPCM(view, 44, this.samples)

    const blob = new Blob([view], { type: "audio/wav" })

    return URL.createObjectURL(blob)
  }

  floatTo16BitPCM(output, offset, input) {
    for (let i = 0; i < input.length; i++, offset += 2) {
      let s = Math.max(-1, Math.min(1, input[i]))
      output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true)
    }
  }

  joinSamples() {
    let recordLength = this.samples.length * this.bufferSize
    let joinedSamples = new Float64Array(recordLength)
    let offset = 0

    for (let i = 0; i < this.samples.length; i++) {
      let sample = this.samples[i]
      joinedSamples.set(sample, offset)
      offset += sample.length
    }

    this.samples = joinedSamples
  }

  writeString(view, offset, string) {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i))
    }
  }
}
```

## 参考

[ユーザーから音声データを取得する | Web | Google Developers](https://developers.google.com/web/fundamentals/media/recording-audio?hl=ja)

[Inside WebM](https://www.slideshare.net/mganeko/inside-webm)

[GitHub - grishkovelli/vue-audio-recorder: A simple audio recorder for VueJS applications](https://github.com/grishkovelli/vue-audio-recorder)

[WAVEファイルの構造](http://www.graffiti.jp/pc/p030506a.htm)
